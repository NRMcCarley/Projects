{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oAw85X3Ga_m",
        "outputId": "858e7e37-2795-4aa5-fffc-32fedde17dda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.57.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Collecting keras<2.14,>=2.13.1 (from tensorflow)\n",
            "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Collecting tensorboard<2.14,>=2.13 (from tensorflow)\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow)\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.33.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
            "Installing collected packages: typing-extensions, tensorflow-estimator, keras, tensorboard, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.7.1\n",
            "    Uninstalling typing_extensions-4.7.1:\n",
            "      Successfully uninstalled typing_extensions-4.7.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.3\n",
            "    Uninstalling tensorboard-2.12.3:\n",
            "      Successfully uninstalled tensorboard-2.12.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pydantic 2.2.1 requires typing-extensions>=4.6.1, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic-core 2.6.1 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.13.1 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 typing-extensions-4.5.0\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xn5uKY-io0wM",
        "outputId": "fe935ba3-a51d-424e-cbbc-87abf6349329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.13.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Embedding, MultiHeadAttention, LayerNormalization, Dropout, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDpXVKF7ft7m"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5y9aJF8cvMqA"
      },
      "outputs": [],
      "source": [
        "D_MODEL = 512                      # Model dimension\n",
        "NUM_HEADS = 8                      # Number of heads\n",
        "D_K = int(D_MODEL / NUM_HEADS)     # Dimension of Q and K\n",
        "D_V = D_K                          # Dimension of V\n",
        "NUM_LAYERS = 3                     # Number of Encoder/Decoder Stacks\n",
        "D_FF = 2048                        # Number of neurons in Feed Forward layer\n",
        "MAX_TOKENS = 100                   # Maximum number of tokens in a sequence\n",
        "DROPOUT_RATE = 0.1                 # Gloabl dropout rate\n",
        "maxTokenLen = 25\n",
        "epsilon = 0.0000001"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko6WVuaMl2hh"
      },
      "source": [
        "# **1. Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sv-0k_9lz34",
        "outputId": "af9e5646-e898-4de1-cdb6-af3a60c86471"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-6b997c1ed99f>:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'Word':space}, ignore_index=True)\n"
          ]
        }
      ],
      "source": [
        "sheet_url = \"https://docs.google.com/spreadsheets/d/1jipqsnc_L5Il90fX93yYtTlr_H7tNFB_Z5N2U2WsafM/edit#gid=0\"\n",
        "url_1 = sheet_url.replace('/edit#gid=', '/export?format=csv&gid=')\n",
        "\n",
        "df = pd.read_csv(url_1)\n",
        "space = ' '\n",
        "df = df.append({'Word':space}, ignore_index=True)\n",
        "startToken = tf.convert_to_tensor([['<']])\n",
        "words = list(df)\n",
        "df_vocab = df[words].astype(str)\n",
        "Vocab = df_vocab.to_numpy()\n",
        "\n",
        "VOCAB_SIZE = np.shape(Vocab)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4X22sM2Nmbsd"
      },
      "outputs": [],
      "source": [
        "def getVocabIdx(word):\n",
        "  # Takes in str of word, return int of vocab index\n",
        "  return df.index[df['Word'] == word].to_list()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "et3TcqzOmgfC"
      },
      "outputs": [],
      "source": [
        "token_length_to_index = {}\n",
        "for idx, row in df.iterrows():\n",
        "    if pd.notna(row['Word']):\n",
        "        token_len = len(row['Word'])\n",
        "        if token_len not in token_length_to_index:\n",
        "            token_length_to_index[token_len] = []\n",
        "        token_length_to_index[token_len].append((row['Word'], getVocabIdx(row['Word'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C56ylSiRoFD1"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_pad_training(inputStrList):\n",
        "  # Returns array of (samples, MAX_TOKENS+1) in order to get the right dimensions for Y\n",
        "  global MAX_TOKENS\n",
        "  # Initialize an empty list to store tokenized and padded sequences\n",
        "  tokenized_sequences = []\n",
        "\n",
        "  for inputStr in inputStrList:\n",
        "      tokens = []\n",
        "      charIdx = 0\n",
        "      numChars = len(inputStr)\n",
        "\n",
        "      while charIdx < numChars:\n",
        "          found_token = False\n",
        "          for windowSize in range(min(maxTokenLen, numChars - charIdx), 0, -1):\n",
        "              token = inputStr[charIdx:charIdx + windowSize]\n",
        "              if token_length_to_index.get(windowSize) is not None:\n",
        "                  for word, vocab_idx in token_length_to_index[windowSize]:\n",
        "                      if word == token:\n",
        "                          tokens.append(vocab_idx)\n",
        "                          charIdx += windowSize\n",
        "                          found_token = True\n",
        "                          break\n",
        "              if found_token:\n",
        "                  break\n",
        "          if not found_token:\n",
        "              charIdx += 1\n",
        "\n",
        "      # Add start (1) and end (2) tokens before and after the sentence\n",
        "      tokens = [1] + tokens + [2]\n",
        "\n",
        "      # Pad or truncate the tokens to maxSeqLen\n",
        "      tokens = tokens[:MAX_TOKENS] + [0] * (MAX_TOKENS+1 - len(tokens))\n",
        "\n",
        "      tokenized_sequences.append(tokens)\n",
        "\n",
        "  # Convert the list of tokenized sequences to a NumPy array\n",
        "  output = np.array(tokenized_sequences)\n",
        "\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "294RL6dFm62Q"
      },
      "outputs": [],
      "source": [
        "textX = ['What is the meaning of life?',\n",
        "        'How does photosynthesis work?',\n",
        "        'What is gravity?',\n",
        "        'How many eggs are in a dozen?',\n",
        "        'What is the capital of France?']\n",
        "textY = ['The meaning of life is a philosophical question that has been debated for centuries.',\n",
        "        'Photosynthesis is the process by which plants use sunlight, carbon dioxide, and water to produce glucose (sugar) and oxygen.',\n",
        "        'Gravity is the force of attraction between two objects with mass.',\n",
        "        'There are twelve eggs in a dozen.',\n",
        "        'The capital of France is Paris.']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUiIK7K86vfE"
      },
      "outputs": [],
      "source": [
        "tokensX = tokenize_and_pad_training(textX)[:, 0:MAX_TOKENS]\n",
        "tokensY = tokenize_and_pad_training(textY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QeqxN2NNgMd"
      },
      "outputs": [],
      "source": [
        "inputX = tokensX\n",
        "inputY = tokensY[:,:-1]\n",
        "trueY = tokensY[:,1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKvNQalOJPsJ"
      },
      "outputs": [],
      "source": [
        "inputX = inputX.astype(np.int32)\n",
        "inputY = inputY.astype(np.int32)\n",
        "inputY[inputY == 2] = 0\n",
        "trueY = trueY.astype(np.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYHTxUHSsnxJ"
      },
      "outputs": [],
      "source": [
        "# testing\n",
        "sample = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWHeH9rBpuZY",
        "outputId": "d92731ad-f5e9-4926-dd17-d8193e31f072"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    1,    10, 15908, 30086,   273, 30086,   540,  6950,  6074,\n",
              "       30086,   210,    68,     2,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "inputX[sample,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhX3_VGPpvkf",
        "outputId": "77eccb27-40c3-43b7-e7d0-f73e12667362"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    1,    18,   572,  1929,  6950,  6074, 30086,    93, 30086,\n",
              "          86, 30086,   516, 30086,    96, 30086,   142, 30086,  2325,\n",
              "       30086,   146, 30086, 13054,    65, 30086,  3829, 30086, 11202,\n",
              "          65, 30086,    88, 30086,   419, 30086,    89, 30086,  2358,\n",
              "       30086,  9767, 30086,    70,  3468,    71, 30086,    88, 30086,\n",
              "        5643,    66,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "inputY[sample,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Uz-9xDWpvhL",
        "outputId": "4e6742d3-7bb2-4cb8-b28a-b5851595f1f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   18,   572,  1929,  6950,  6074, 30086,    93, 30086,    86,\n",
              "       30086,   516, 30086,    96, 30086,   142, 30086,  2325, 30086,\n",
              "         146, 30086, 13054,    65, 30086,  3829, 30086, 11202,    65,\n",
              "       30086,    88, 30086,   419, 30086,    89, 30086,  2358, 30086,\n",
              "        9767, 30086,    70,  3468,    71, 30086,    88, 30086,  5643,\n",
              "          66,     2,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "trueY[sample,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0Tr0B2rAfmk"
      },
      "outputs": [],
      "source": [
        "NUM_SAMPLES = np.shape(inputX)[0]\n",
        "\n",
        "numToTrain = int(np.round(0.8 * NUM_SAMPLES))\n",
        "\n",
        "inputX_train = inputX[0:numToTrain, :]\n",
        "inputX_val = inputX[numToTrain:NUM_SAMPLES+1, :]\n",
        "\n",
        "inputY_train = inputY[0:numToTrain,:]\n",
        "inputY_val = inputY[numToTrain:NUM_SAMPLES+1, :]\n",
        "\n",
        "trueY_train = trueY[0:numToTrain,:]\n",
        "trueY_val = trueY[numToTrain:NUM_SAMPLES+1, :]\n",
        "\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "# Prepare the training dataset.\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(((inputX_train, inputY_train), trueY_train))     # slices along the first axis of both sets\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)     # creates batches of slices, of size batch_size\n",
        "\n",
        "# Prepare the validation dataset.\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices(((inputX_val, inputY_val), trueY_val))\n",
        "val_dataset = val_dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79G-K2DA2g9D",
        "outputId": "e59691c3-449e-4389-cbba-c86780555d22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=((TensorSpec(shape=(None, 100), dtype=tf.int32, name=None), TensorSpec(shape=(None, 100), dtype=tf.int32, name=None)), TensorSpec(shape=(None, 100), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "train_dataset\n",
        "val_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPStSDeHoEy7"
      },
      "source": [
        "#**2. Testing the Functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUFbkmXza1wq"
      },
      "outputs": [],
      "source": [
        "for (batch, ((x_batch_train, y_batch_train), true_y_batch_train)) in enumerate(train_dataset):\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9izWvxhDUBHb",
        "outputId": "98f1e9df-4d6b-4226-dbcc-49f1c15363d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[    1    10 15908 30086   273 30086   540  6950  6074 30086   210    68\n",
            "      2     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]], shape=(1, 100), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[    1    18   572  1929  6950  6074 30086    93 30086    86 30086   516\n",
            "  30086    96 30086   142 30086  2325 30086   146 30086 13054    65 30086\n",
            "   3829 30086 11202    65 30086    88 30086   419 30086    89 30086  2358\n",
            "  30086  9767 30086    70  3468    71 30086    88 30086  5643    66     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]], shape=(1, 100), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[   18   572  1929  6950  6074 30086    93 30086    86 30086   516 30086\n",
            "     96 30086   142 30086  2325 30086   146 30086 13054    65 30086  3829\n",
            "  30086 11202    65 30086    88 30086   419 30086    89 30086  2358 30086\n",
            "   9767 30086    70  3468    71 30086    88 30086  5643    66     2     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]], shape=(1, 100), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "print(x_batch_train)\n",
        "print(y_batch_train)\n",
        "print(true_y_batch_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-PSXhkjfP_C"
      },
      "source": [
        "2.1 Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OLXFMu_B6Od"
      },
      "outputs": [],
      "source": [
        "def positional_encoding(length, depth):\n",
        "  depth = depth/2\n",
        "\n",
        "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
        "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
        "\n",
        "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
        "  angle_rads = positions * angle_rates      # (pos, depth)\n",
        "\n",
        "  pos_encoding = np.concatenate(\n",
        "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
        "      axis=-1)\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "\n",
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "  def __init__(self, vocab_size, d_model):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)  # Add mask_zero=True here\n",
        "    self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
        "\n",
        "  def compute_mask(self, inputs, mask=None):\n",
        "    # The mask returned by this layer is the same as the one received (identity mask).\n",
        "    return mask\n",
        "\n",
        "  def call(self, x, mask=None):\n",
        "    length = tf.shape(x)[1]\n",
        "    x = self.embedding(x)\n",
        "    # This factor sets the relative scale of the embedding and positional_encoding.\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXv92nrLbWXO",
        "outputId": "168c16df-2e0a-461b-8819-e54eb715fa0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_emb shape: (1, 100, 512)\n",
            "y_emb shape: (1, 100, 512)\n"
          ]
        }
      ],
      "source": [
        "# We only use one embedder since the input and output vocab are the same\n",
        "# (use two embedders if it's a vision transformer, one language to another\n",
        "# language, etc)\n",
        "gen_embed = PositionalEmbedding(vocab_size=VOCAB_SIZE, d_model=D_MODEL)\n",
        "\n",
        "x_emb = gen_embed(x_batch_train)\n",
        "y_emb = gen_embed(y_batch_train)\n",
        "\n",
        "print(f'x_emb shape: {x_emb.shape}')\n",
        "print(f'y_emb shape: {y_emb.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9H2c3tafK97"
      },
      "source": [
        "2.2 Attention Types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndbZdsnherfT"
      },
      "outputs": [],
      "source": [
        "class BaseAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9oeNFGZg-at"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(BaseAttention):\n",
        "  def call(self, x, context):\n",
        "    attn_output, attn_scores = self.mha(\n",
        "        query=x,\n",
        "        key=context,\n",
        "        value=context,\n",
        "        return_attention_scores=True)\n",
        "\n",
        "    # Cache the attention scores for plotting later.\n",
        "    self.last_attn_scores = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB-1hWxRhixU",
        "outputId": "f60cac45-4b9b-4c2a-c849-d0a0d10f7e8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 100, 512)\n"
          ]
        }
      ],
      "source": [
        "sample_ca = CrossAttention(num_heads=2, key_dim=512)\n",
        "\n",
        "print(sample_ca(x_emb, y_emb).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPlU_qP4hxxW"
      },
      "outputs": [],
      "source": [
        "class GlobalSelfAttention(BaseAttention):\n",
        "  def call(self, x):\n",
        "    attn_output = self.mha(\n",
        "        query=x,\n",
        "        value=x,\n",
        "        key=x)\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aGce32gh0N4",
        "outputId": "24762a34-5cd8-4391-ded5-35eb05515b17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 100, 512)\n"
          ]
        }
      ],
      "source": [
        "sample_gsa = GlobalSelfAttention(num_heads=2, key_dim=512)\n",
        "\n",
        "print(sample_gsa(x_emb).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7goP8Fah8ak"
      },
      "outputs": [],
      "source": [
        "class CausalSelfAttention(BaseAttention):\n",
        "  def call(self, x):\n",
        "    attn_output = self.mha(\n",
        "        query=x,\n",
        "        value=x,\n",
        "        key=x,\n",
        "        use_causal_mask = True)\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21ToRnJKh-2v",
        "outputId": "679a6f11-d91f-4226-b69a-239ab68c0480"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 100, 512)\n"
          ]
        }
      ],
      "source": [
        "sample_csa = CausalSelfAttention(num_heads=2, key_dim=512)\n",
        "\n",
        "print(sample_csa(y_emb).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiE7vQy-mC8_"
      },
      "source": [
        "Feed Forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QTDKCvoiUMf"
      },
      "outputs": [],
      "source": [
        "class FeedForward(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.seq = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),\n",
        "      tf.keras.layers.Dense(d_model),\n",
        "      tf.keras.layers.Dropout(dropout_rate)\n",
        "    ])\n",
        "    self.add = tf.keras.layers.Add()\n",
        "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.add([x, self.seq(x)])\n",
        "    x = self.layer_norm(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWBY6gcNiXQP",
        "outputId": "58e2a1e6-2889-47dd-a138-219aef66c6b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 100, 512)\n"
          ]
        }
      ],
      "source": [
        "sample_ffn = FeedForward(512, 2048)\n",
        "\n",
        "print(sample_ffn(y_emb).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5v1bgGlmEmc"
      },
      "source": [
        "Encoder Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOJ3b50eicKj"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.self_attention = GlobalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.self_attention(x)\n",
        "    x = self.ffn(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpQNq_GsiejQ",
        "outputId": "5eb15052-03eb-43af-b750-9811249b6087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 100, 512)\n"
          ]
        }
      ],
      "source": [
        "sample_encoder_layer = EncoderLayer(d_model=512, num_heads=8, dff=2048)\n",
        "\n",
        "print(sample_encoder_layer(x_emb).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54iNeucomGEM"
      },
      "source": [
        "Encoder Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omnGSw1eioHM"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads,\n",
        "               dff, vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.pos_embedding = PositionalEmbedding(\n",
        "        vocab_size=vocab_size, d_model=d_model)\n",
        "\n",
        "    self.enc_layers = [\n",
        "        EncoderLayer(d_model=d_model,\n",
        "                     num_heads=num_heads,\n",
        "                     dff=dff,\n",
        "                     dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  def call(self, x):\n",
        "    # `x` is token-IDs shape: (batch, seq_len)\n",
        "    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "\n",
        "    # Add dropout.\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x)\n",
        "\n",
        "    return x  # Shape `(batch_size, seq_len, d_model)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqSq5FQliq7Q",
        "outputId": "894dff02-89c9-4678-bcb4-71f78335df2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 100, 512)\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder.\n",
        "sample_encoder = Encoder(num_layers=4,\n",
        "                         d_model=512,\n",
        "                         num_heads=8,\n",
        "                         dff=2048,\n",
        "                         vocab_size=VOCAB_SIZE)\n",
        "\n",
        "sample_encoder_output = sample_encoder(x_batch_train, training=False)\n",
        "\n",
        "# Print the shape.\n",
        "print(sample_encoder_output.shape)  # Shape `(batch_size, input_seq_len, d_model)`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZpz1V_EmHuG"
      },
      "source": [
        "Decoder Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUPXEdXmi7xE"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,\n",
        "               *,\n",
        "               d_model,\n",
        "               num_heads,\n",
        "               dff,\n",
        "               dropout_rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.causal_self_attention = CausalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.cross_attention = CrossAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x, context):\n",
        "    x = self.causal_self_attention(x=x)\n",
        "    x = self.cross_attention(x=x, context=context)\n",
        "\n",
        "    # Cache the last attention scores for plotting later\n",
        "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
        "\n",
        "    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGL40ZOli-jU",
        "outputId": "74a868af-0265-4999-a51b-e31d42f02840"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 100, 512)\n"
          ]
        }
      ],
      "source": [
        "sample_decoder_layer = DecoderLayer(d_model=512, num_heads=8, dff=2048)\n",
        "\n",
        "sample_decoder_layer_output = sample_decoder_layer(\n",
        "    x=y_emb, context=x_emb)\n",
        "\n",
        "print(sample_decoder_layer_output.shape)  # `(batch_size, seq_len, d_model)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX85cKoXmI84"
      },
      "source": [
        "Decoder Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UgSPTi5jQUp"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n",
        "               dropout_rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
        "                                             d_model=d_model)\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "    self.dec_layers = [\n",
        "        DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
        "                     dff=dff, dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)]\n",
        "\n",
        "    self.last_attn_scores = None\n",
        "\n",
        "  def call(self, x, context):\n",
        "    # `x` is token-IDs shape (batch, target_seq_len)\n",
        "    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x  = self.dec_layers[i](x, context)\n",
        "\n",
        "    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
        "\n",
        "    # The shape of x is (batch_size, target_seq_len, d_model).\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RaOK1QAjgBa",
        "outputId": "88cca4b8-1e57-4125-9dd0-8ce5c937db98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 100)\n",
            "(1, 100, 512)\n",
            "(1, 100, 512)\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the decoder.\n",
        "sample_decoder = Decoder(num_layers=4,\n",
        "                         d_model=512,\n",
        "                         num_heads=8,\n",
        "                         dff=2048,\n",
        "                         vocab_size=VOCAB_SIZE)\n",
        "\n",
        "output = sample_decoder(\n",
        "    x = y_batch_train,\n",
        "    context = x_emb)\n",
        "\n",
        "# Print the shapes.\n",
        "print(x_batch_train.shape)\n",
        "print(x_emb.shape)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdmCwLnMj0dY",
        "outputId": "e6d8429f-4482-4ece-d1b8-7ab5fe42183e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 8, 100, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "sample_decoder.last_attn_scores.shape  # (batch, heads, target_seq, input_seq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "by7yuFVVmK2F"
      },
      "source": [
        "Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "froRd4tGkDC-"
      },
      "outputs": [],
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
        "               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
        "                           num_heads=num_heads, dff=dff,\n",
        "                           vocab_size=input_vocab_size,\n",
        "                           dropout_rate=dropout_rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
        "                           num_heads=num_heads, dff=dff,\n",
        "                           vocab_size=target_vocab_size,\n",
        "                           dropout_rate=dropout_rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # To use a Keras model with `.fit` you must pass all your inputs in the\n",
        "    # first argument.\n",
        "    context, x  = inputs\n",
        "\n",
        "    context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
        "\n",
        "    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
        "\n",
        "    # Final linear layer output.\n",
        "    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
        "\n",
        "    try:\n",
        "      # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
        "      # b/250038731\n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    # Return the final output and the attention weights.\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BePZC7TlkM0i"
      },
      "outputs": [],
      "source": [
        "transformer = Transformer(\n",
        "    num_layers = NUM_LAYERS,\n",
        "    d_model = D_MODEL,\n",
        "    num_heads = NUM_HEADS,\n",
        "    dff = D_FF,\n",
        "    input_vocab_size = VOCAB_SIZE,\n",
        "    target_vocab_size = VOCAB_SIZE,\n",
        "    dropout_rate = DROPOUT_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBhpzxIekToE",
        "outputId": "ed6bfa7a-5665-41a7-9929-636927c655ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 100)\n",
            "(1, 100)\n",
            "(1, 100, 30087)\n",
            "(1, 100)\n"
          ]
        }
      ],
      "source": [
        "output = transformer((x_batch_train, y_batch_train))\n",
        "\n",
        "print(y_batch_train.shape)\n",
        "print(x_batch_train.shape)\n",
        "print(output.shape)\n",
        "print(true_y_batch_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Qdu7bSlkhDv",
        "outputId": "2a2e728f-54e1-44e1-e213-922100cb7d0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 8, 100, 100)\n"
          ]
        }
      ],
      "source": [
        "attn_scores = transformer.decoder.dec_layers[-1].last_attn_scores\n",
        "print(attn_scores.shape)  # (batch, heads, target_seq, input_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0MFxLwzkg-V",
        "outputId": "5c42c784-631b-4137-fe48-8e30ca9f16c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_2 (Encoder)         multiple                  46914048  \n",
            "                                                                 \n",
            " decoder_2 (Decoder)         multiple                  72121344  \n",
            "                                                                 \n",
            " dense_47 (Dense)            multiple                  15434631  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134470023 (512.96 MB)\n",
            "Trainable params: 134470023 (512.96 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "transformer.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMzZAlecmMzh"
      },
      "source": [
        "Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JqKNry3lxnu"
      },
      "outputs": [],
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    step = tf.cast(step, dtype=tf.float32)\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQwMWhRbl3jy"
      },
      "outputs": [],
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "F8AHnuqOl5um",
        "outputId": "ca6bac59-dbe4-422b-9f39-2f0c468529bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "metadata": {},
          "execution_count": 72
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(learning_rate(tf.range(40000, dtype=tf.float32)))\n",
        "plt.ylabel('Learning Rate')\n",
        "plt.xlabel('Train Step')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGBSaHWgrj-e"
      },
      "source": [
        "Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hm69DrQJmSO_"
      },
      "outputs": [],
      "source": [
        "def masked_loss(label, pred):\n",
        "  mask = label != 0\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "  loss = loss_object(label, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)\n",
        "  loss *= mask\n",
        "\n",
        "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
        "  return loss\n",
        "\n",
        "\n",
        "def masked_accuracy(label, pred):\n",
        "  pred = tf.argmax(pred, axis=2)\n",
        "  label = tf.cast(label, pred.dtype)\n",
        "  match = label == pred\n",
        "\n",
        "  mask = label != 0\n",
        "\n",
        "  match = match & mask\n",
        "\n",
        "  match = tf.cast(match, dtype=tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "  return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VqXSa2ZrlXY"
      },
      "source": [
        "Compile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32j91cSYmbBj"
      },
      "outputs": [],
      "source": [
        "transformer.compile(\n",
        "    loss=masked_loss,\n",
        "    optimizer=optimizer,\n",
        "    metrics=[masked_accuracy])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfJIoYvLrmOL"
      },
      "source": [
        "Fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pFXkNd2tKB9",
        "outputId": "c991164e-d6c4-4688-f721-307441175f81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "4/4 [==============================] - 29s 1s/step - loss: 10.2983 - masked_accuracy: 0.0000e+00 - val_loss: 10.2466 - val_masked_accuracy: 0.0000e+00\n",
            "Epoch 2/200\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 10.2480 - masked_accuracy: 0.0000e+00 - val_loss: 10.2206 - val_masked_accuracy: 0.0000e+00\n",
            "Epoch 3/200\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 10.2128 - masked_accuracy: 0.0000e+00 - val_loss: 10.1755 - val_masked_accuracy: 0.0000e+00\n",
            "Epoch 4/200\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 10.1457 - masked_accuracy: 0.0083 - val_loss: 10.1135 - val_masked_accuracy: 0.0556\n",
            "Epoch 5/200\n",
            "4/4 [==============================] - 1s 303ms/step - loss: 10.0433 - masked_accuracy: 0.1159 - val_loss: 10.0345 - val_masked_accuracy: 0.2222\n",
            "Epoch 6/200\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 9.9157 - masked_accuracy: 0.3408 - val_loss: 9.9413 - val_masked_accuracy: 0.2778\n",
            "Epoch 7/200\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 9.7963 - masked_accuracy: 0.3978 - val_loss: 9.8365 - val_masked_accuracy: 0.2778\n",
            "Epoch 8/200\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 9.6381 - masked_accuracy: 0.3978 - val_loss: 9.7248 - val_masked_accuracy: 0.2778\n",
            "Epoch 9/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 9.4853 - masked_accuracy: 0.3978 - val_loss: 9.6104 - val_masked_accuracy: 0.2778\n",
            "Epoch 10/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 9.3128 - masked_accuracy: 0.3978 - val_loss: 9.4996 - val_masked_accuracy: 0.2778\n",
            "Epoch 11/200\n",
            "4/4 [==============================] - 1s 283ms/step - loss: 9.1584 - masked_accuracy: 0.3978 - val_loss: 9.3979 - val_masked_accuracy: 0.2778\n",
            "Epoch 12/200\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 9.0183 - masked_accuracy: 0.3978 - val_loss: 9.3061 - val_masked_accuracy: 0.2778\n",
            "Epoch 13/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 8.8897 - masked_accuracy: 0.3978 - val_loss: 9.2247 - val_masked_accuracy: 0.2778\n",
            "Epoch 14/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 8.7798 - masked_accuracy: 0.3978 - val_loss: 9.1525 - val_masked_accuracy: 0.2778\n",
            "Epoch 15/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 8.6833 - masked_accuracy: 0.3978 - val_loss: 9.0912 - val_masked_accuracy: 0.2778\n",
            "Epoch 16/200\n",
            "4/4 [==============================] - 0s 92ms/step - loss: 8.6072 - masked_accuracy: 0.3978 - val_loss: 9.0389 - val_masked_accuracy: 0.2778\n",
            "Epoch 17/200\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 8.5386 - masked_accuracy: 0.3978 - val_loss: 8.9929 - val_masked_accuracy: 0.2778\n",
            "Epoch 18/200\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 8.4733 - masked_accuracy: 0.3978 - val_loss: 8.9517 - val_masked_accuracy: 0.2778\n",
            "Epoch 19/200\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 8.4155 - masked_accuracy: 0.3978 - val_loss: 8.9121 - val_masked_accuracy: 0.2778\n",
            "Epoch 20/200\n",
            "4/4 [==============================] - 0s 116ms/step - loss: 8.3577 - masked_accuracy: 0.3978 - val_loss: 8.8750 - val_masked_accuracy: 0.2778\n",
            "Epoch 21/200\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 8.2939 - masked_accuracy: 0.3978 - val_loss: 8.8345 - val_masked_accuracy: 0.2778\n",
            "Epoch 22/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 8.2437 - masked_accuracy: 0.3978 - val_loss: 8.7943 - val_masked_accuracy: 0.2778\n",
            "Epoch 23/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 8.1882 - masked_accuracy: 0.3978 - val_loss: 8.7555 - val_masked_accuracy: 0.2778\n",
            "Epoch 24/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 8.1273 - masked_accuracy: 0.3978 - val_loss: 8.7133 - val_masked_accuracy: 0.2778\n",
            "Epoch 25/200\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 8.0642 - masked_accuracy: 0.3978 - val_loss: 8.6706 - val_masked_accuracy: 0.2778\n",
            "Epoch 26/200\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 8.0083 - masked_accuracy: 0.3978 - val_loss: 8.6293 - val_masked_accuracy: 0.2778\n",
            "Epoch 27/200\n",
            "4/4 [==============================] - 0s 112ms/step - loss: 7.9509 - masked_accuracy: 0.3978 - val_loss: 8.5836 - val_masked_accuracy: 0.2778\n",
            "Epoch 28/200\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 7.8807 - masked_accuracy: 0.3978 - val_loss: 8.5380 - val_masked_accuracy: 0.2778\n",
            "Epoch 29/200\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 7.8133 - masked_accuracy: 0.3978 - val_loss: 8.4887 - val_masked_accuracy: 0.2778\n",
            "Epoch 30/200\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 7.7423 - masked_accuracy: 0.3978 - val_loss: 8.4383 - val_masked_accuracy: 0.2778\n",
            "Epoch 31/200\n",
            "4/4 [==============================] - 0s 120ms/step - loss: 7.6638 - masked_accuracy: 0.3978 - val_loss: 8.3862 - val_masked_accuracy: 0.2778\n",
            "Epoch 32/200\n",
            "4/4 [==============================] - 1s 268ms/step - loss: 7.5869 - masked_accuracy: 0.3978 - val_loss: 8.3296 - val_masked_accuracy: 0.2778\n",
            "Epoch 33/200\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 7.5099 - masked_accuracy: 0.3978 - val_loss: 8.2736 - val_masked_accuracy: 0.2778\n",
            "Epoch 34/200\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 7.4303 - masked_accuracy: 0.3978 - val_loss: 8.2132 - val_masked_accuracy: 0.2778\n",
            "Epoch 35/200\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 7.3413 - masked_accuracy: 0.3978 - val_loss: 8.1498 - val_masked_accuracy: 0.2778\n",
            "Epoch 36/200\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 7.2578 - masked_accuracy: 0.3978 - val_loss: 8.0861 - val_masked_accuracy: 0.2778\n",
            "Epoch 37/200\n",
            "4/4 [==============================] - 0s 113ms/step - loss: 7.1707 - masked_accuracy: 0.3978 - val_loss: 8.0199 - val_masked_accuracy: 0.2778\n",
            "Epoch 38/200\n",
            "4/4 [==============================] - 1s 263ms/step - loss: 7.0684 - masked_accuracy: 0.3978 - val_loss: 7.9506 - val_masked_accuracy: 0.2778\n",
            "Epoch 39/200\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 6.9704 - masked_accuracy: 0.3978 - val_loss: 7.8777 - val_masked_accuracy: 0.2778\n",
            "Epoch 40/200\n",
            "4/4 [==============================] - 1s 288ms/step - loss: 6.8697 - masked_accuracy: 0.3978 - val_loss: 7.8035 - val_masked_accuracy: 0.2778\n",
            "Epoch 41/200\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 6.7709 - masked_accuracy: 0.3978 - val_loss: 7.7301 - val_masked_accuracy: 0.2778\n",
            "Epoch 42/200\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 6.6578 - masked_accuracy: 0.3978 - val_loss: 7.6514 - val_masked_accuracy: 0.2778\n",
            "Epoch 43/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 6.5502 - masked_accuracy: 0.3978 - val_loss: 7.5685 - val_masked_accuracy: 0.2778\n",
            "Epoch 44/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 6.4410 - masked_accuracy: 0.3978 - val_loss: 7.4913 - val_masked_accuracy: 0.2778\n",
            "Epoch 45/200\n",
            "4/4 [==============================] - 0s 102ms/step - loss: 6.3263 - masked_accuracy: 0.3978 - val_loss: 7.4138 - val_masked_accuracy: 0.2778\n",
            "Epoch 46/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 6.2091 - masked_accuracy: 0.3978 - val_loss: 7.3347 - val_masked_accuracy: 0.2778\n",
            "Epoch 47/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 6.0886 - masked_accuracy: 0.3978 - val_loss: 7.2497 - val_masked_accuracy: 0.2778\n",
            "Epoch 48/200\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 5.9756 - masked_accuracy: 0.3978 - val_loss: 7.1665 - val_masked_accuracy: 0.2778\n",
            "Epoch 49/200\n",
            "4/4 [==============================] - 0s 119ms/step - loss: 5.8511 - masked_accuracy: 0.3978 - val_loss: 7.0925 - val_masked_accuracy: 0.2778\n",
            "Epoch 50/200\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 5.7349 - masked_accuracy: 0.3978 - val_loss: 7.0083 - val_masked_accuracy: 0.3333\n",
            "Epoch 51/200\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 5.6084 - masked_accuracy: 0.3978 - val_loss: 6.9193 - val_masked_accuracy: 0.3333\n",
            "Epoch 52/200\n",
            "4/4 [==============================] - 1s 281ms/step - loss: 5.4867 - masked_accuracy: 0.4062 - val_loss: 6.8430 - val_masked_accuracy: 0.3333\n",
            "Epoch 53/200\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 5.3633 - masked_accuracy: 0.4135 - val_loss: 6.7567 - val_masked_accuracy: 0.3333\n",
            "Epoch 54/200\n",
            "4/4 [==============================] - 1s 278ms/step - loss: 5.2331 - masked_accuracy: 0.4062 - val_loss: 6.6733 - val_masked_accuracy: 0.3333\n",
            "Epoch 55/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 5.1138 - masked_accuracy: 0.4218 - val_loss: 6.6023 - val_masked_accuracy: 0.3333\n",
            "Epoch 56/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 4.9787 - masked_accuracy: 0.3978 - val_loss: 6.5088 - val_masked_accuracy: 0.3333\n",
            "Epoch 57/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 4.8560 - masked_accuracy: 0.3978 - val_loss: 6.4301 - val_masked_accuracy: 0.2778\n",
            "Epoch 58/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 4.7293 - masked_accuracy: 0.3978 - val_loss: 6.3528 - val_masked_accuracy: 0.2778\n",
            "Epoch 59/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 4.6071 - masked_accuracy: 0.3978 - val_loss: 6.2757 - val_masked_accuracy: 0.2778\n",
            "Epoch 60/200\n",
            "4/4 [==============================] - 1s 316ms/step - loss: 4.4799 - masked_accuracy: 0.3978 - val_loss: 6.2060 - val_masked_accuracy: 0.2778\n",
            "Epoch 61/200\n",
            "4/4 [==============================] - 0s 109ms/step - loss: 4.3592 - masked_accuracy: 0.3978 - val_loss: 6.1303 - val_masked_accuracy: 0.2778\n",
            "Epoch 62/200\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 4.2413 - masked_accuracy: 0.3978 - val_loss: 6.0669 - val_masked_accuracy: 0.2778\n",
            "Epoch 63/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 4.1249 - masked_accuracy: 0.3978 - val_loss: 5.9992 - val_masked_accuracy: 0.2778\n",
            "Epoch 64/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 4.0079 - masked_accuracy: 0.3978 - val_loss: 5.9419 - val_masked_accuracy: 0.2778\n",
            "Epoch 65/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 3.9029 - masked_accuracy: 0.3978 - val_loss: 5.8913 - val_masked_accuracy: 0.2778\n",
            "Epoch 66/200\n",
            "4/4 [==============================] - 1s 307ms/step - loss: 3.7865 - masked_accuracy: 0.3978 - val_loss: 5.8313 - val_masked_accuracy: 0.2778\n",
            "Epoch 67/200\n",
            "4/4 [==============================] - 0s 120ms/step - loss: 3.6920 - masked_accuracy: 0.3978 - val_loss: 5.7813 - val_masked_accuracy: 0.2778\n",
            "Epoch 68/200\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 3.5888 - masked_accuracy: 0.3978 - val_loss: 5.7428 - val_masked_accuracy: 0.2778\n",
            "Epoch 69/200\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 3.4915 - masked_accuracy: 0.3978 - val_loss: 5.6951 - val_masked_accuracy: 0.2778\n",
            "Epoch 70/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 3.4021 - masked_accuracy: 0.3978 - val_loss: 5.6634 - val_masked_accuracy: 0.2778\n",
            "Epoch 71/200\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 3.3079 - masked_accuracy: 0.3978 - val_loss: 5.6180 - val_masked_accuracy: 0.2778\n",
            "Epoch 72/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 3.2152 - masked_accuracy: 0.3978 - val_loss: 5.5881 - val_masked_accuracy: 0.2778\n",
            "Epoch 73/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 3.1334 - masked_accuracy: 0.4135 - val_loss: 5.5616 - val_masked_accuracy: 0.2778\n",
            "Epoch 74/200\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 3.0533 - masked_accuracy: 0.4218 - val_loss: 5.5348 - val_masked_accuracy: 0.3333\n",
            "Epoch 75/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 2.9710 - masked_accuracy: 0.4318 - val_loss: 5.5267 - val_masked_accuracy: 0.3333\n",
            "Epoch 76/200\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 2.8900 - masked_accuracy: 0.4371 - val_loss: 5.4907 - val_masked_accuracy: 0.3333\n",
            "Epoch 77/200\n",
            "4/4 [==============================] - 1s 281ms/step - loss: 2.8157 - masked_accuracy: 0.4371 - val_loss: 5.5099 - val_masked_accuracy: 0.2778\n",
            "Epoch 78/200\n",
            "4/4 [==============================] - 0s 110ms/step - loss: 2.7454 - masked_accuracy: 0.4371 - val_loss: 5.4676 - val_masked_accuracy: 0.3333\n",
            "Epoch 79/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 2.6649 - masked_accuracy: 0.4371 - val_loss: 5.4372 - val_masked_accuracy: 0.3333\n",
            "Epoch 80/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 2.5978 - masked_accuracy: 0.4371 - val_loss: 5.4247 - val_masked_accuracy: 0.3333\n",
            "Epoch 81/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 2.5207 - masked_accuracy: 0.4611 - val_loss: 5.4601 - val_masked_accuracy: 0.3333\n",
            "Epoch 82/200\n",
            "4/4 [==============================] - 0s 98ms/step - loss: 2.4649 - masked_accuracy: 0.4638 - val_loss: 5.4277 - val_masked_accuracy: 0.3889\n",
            "Epoch 83/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 2.3907 - masked_accuracy: 0.4867 - val_loss: 5.4310 - val_masked_accuracy: 0.3889\n",
            "Epoch 84/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 2.3261 - masked_accuracy: 0.4867 - val_loss: 5.4343 - val_masked_accuracy: 0.3333\n",
            "Epoch 85/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 2.2654 - masked_accuracy: 0.5006 - val_loss: 5.4298 - val_masked_accuracy: 0.3333\n",
            "Epoch 86/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 2.1979 - masked_accuracy: 0.4867 - val_loss: 5.3775 - val_masked_accuracy: 0.3889\n",
            "Epoch 87/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 2.1643 - masked_accuracy: 0.5334 - val_loss: 5.4197 - val_masked_accuracy: 0.3889\n",
            "Epoch 88/200\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 2.0875 - masked_accuracy: 0.5669 - val_loss: 5.3836 - val_masked_accuracy: 0.3889\n",
            "Epoch 89/200\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 2.0464 - masked_accuracy: 0.5302 - val_loss: 5.4100 - val_masked_accuracy: 0.3889\n",
            "Epoch 90/200\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1.9997 - masked_accuracy: 0.5476 - val_loss: 5.3711 - val_masked_accuracy: 0.3889\n",
            "Epoch 91/200\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1.9353 - masked_accuracy: 0.4950 - val_loss: 5.3672 - val_masked_accuracy: 0.3889\n",
            "Epoch 92/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1.8860 - masked_accuracy: 0.6704 - val_loss: 5.3118 - val_masked_accuracy: 0.3889\n",
            "Epoch 93/200\n",
            "4/4 [==============================] - 0s 87ms/step - loss: 1.8114 - masked_accuracy: 0.5649 - val_loss: 5.3916 - val_masked_accuracy: 0.3889\n",
            "Epoch 94/200\n",
            "4/4 [==============================] - 1s 259ms/step - loss: 1.7564 - masked_accuracy: 0.5680 - val_loss: 5.3137 - val_masked_accuracy: 0.3889\n",
            "Epoch 95/200\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1.6943 - masked_accuracy: 0.6614 - val_loss: 5.3577 - val_masked_accuracy: 0.3889\n",
            "Epoch 96/200\n",
            "4/4 [==============================] - 1s 262ms/step - loss: 1.6601 - masked_accuracy: 0.6045 - val_loss: 5.3774 - val_masked_accuracy: 0.3889\n",
            "Epoch 97/200\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1.6076 - masked_accuracy: 0.6774 - val_loss: 5.3494 - val_masked_accuracy: 0.4444\n",
            "Epoch 98/200\n",
            "4/4 [==============================] - 1s 266ms/step - loss: 1.5508 - masked_accuracy: 0.6594 - val_loss: 5.3837 - val_masked_accuracy: 0.3889\n",
            "Epoch 99/200\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1.5057 - masked_accuracy: 0.6954 - val_loss: 5.3137 - val_masked_accuracy: 0.4444\n",
            "Epoch 100/200\n",
            "4/4 [==============================] - 1s 283ms/step - loss: 1.4615 - masked_accuracy: 0.7090 - val_loss: 5.3418 - val_masked_accuracy: 0.4444\n",
            "Epoch 101/200\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.4093 - masked_accuracy: 0.6834 - val_loss: 5.3368 - val_masked_accuracy: 0.4444\n",
            "Epoch 102/200\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.3745 - masked_accuracy: 0.7573 - val_loss: 5.3423 - val_masked_accuracy: 0.4444\n",
            "Epoch 103/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1.3151 - masked_accuracy: 0.7303 - val_loss: 5.3787 - val_masked_accuracy: 0.4444\n",
            "Epoch 104/200\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.2745 - masked_accuracy: 0.7113 - val_loss: 5.3279 - val_masked_accuracy: 0.4444\n",
            "Epoch 105/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1.2368 - masked_accuracy: 0.8146 - val_loss: 5.3803 - val_masked_accuracy: 0.4444\n",
            "Epoch 106/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1.1908 - masked_accuracy: 0.7513 - val_loss: 5.4208 - val_masked_accuracy: 0.4444\n",
            "Epoch 107/200\n",
            "4/4 [==============================] - 0s 101ms/step - loss: 1.1405 - masked_accuracy: 0.8322 - val_loss: 5.3839 - val_masked_accuracy: 0.4444\n",
            "Epoch 108/200\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 1.1033 - masked_accuracy: 0.8593 - val_loss: 5.3844 - val_masked_accuracy: 0.4444\n",
            "Epoch 109/200\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1.0571 - masked_accuracy: 0.8103 - val_loss: 5.3821 - val_masked_accuracy: 0.4444\n",
            "Epoch 110/200\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 1.0129 - masked_accuracy: 0.8905 - val_loss: 5.3864 - val_masked_accuracy: 0.4444\n",
            "Epoch 111/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.9795 - masked_accuracy: 0.8762 - val_loss: 5.4198 - val_masked_accuracy: 0.4444\n",
            "Epoch 112/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.9414 - masked_accuracy: 0.8989 - val_loss: 5.4489 - val_masked_accuracy: 0.4444\n",
            "Epoch 113/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.8943 - masked_accuracy: 0.9035 - val_loss: 5.4772 - val_masked_accuracy: 0.4444\n",
            "Epoch 114/200\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.8561 - masked_accuracy: 0.9125 - val_loss: 5.4957 - val_masked_accuracy: 0.4444\n",
            "Epoch 115/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.8205 - masked_accuracy: 0.9757 - val_loss: 5.5586 - val_masked_accuracy: 0.4444\n",
            "Epoch 116/200\n",
            "4/4 [==============================] - 1s 345ms/step - loss: 0.7724 - masked_accuracy: 0.9544 - val_loss: 5.5233 - val_masked_accuracy: 0.4444\n",
            "Epoch 117/200\n",
            "4/4 [==============================] - 0s 107ms/step - loss: 0.7542 - masked_accuracy: 0.9863 - val_loss: 5.5699 - val_masked_accuracy: 0.4444\n",
            "Epoch 118/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.7153 - masked_accuracy: 0.9704 - val_loss: 5.4856 - val_masked_accuracy: 0.4444\n",
            "Epoch 119/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.6970 - masked_accuracy: 0.9863 - val_loss: 5.5533 - val_masked_accuracy: 0.4444\n",
            "Epoch 120/200\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.6613 - masked_accuracy: 0.9863 - val_loss: 5.5495 - val_masked_accuracy: 0.4444\n",
            "Epoch 121/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.6597 - masked_accuracy: 0.9863 - val_loss: 5.7061 - val_masked_accuracy: 0.4444\n",
            "Epoch 122/200\n",
            "4/4 [==============================] - 1s 311ms/step - loss: 0.6335 - masked_accuracy: 0.9863 - val_loss: 5.5483 - val_masked_accuracy: 0.4444\n",
            "Epoch 123/200\n",
            "4/4 [==============================] - 0s 110ms/step - loss: 0.5853 - masked_accuracy: 0.9863 - val_loss: 5.5925 - val_masked_accuracy: 0.4444\n",
            "Epoch 124/200\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.5680 - masked_accuracy: 0.9863 - val_loss: 5.5609 - val_masked_accuracy: 0.4444\n",
            "Epoch 125/200\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.5325 - masked_accuracy: 0.9863 - val_loss: 5.5667 - val_masked_accuracy: 0.4444\n",
            "Epoch 126/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.4960 - masked_accuracy: 0.9863 - val_loss: 5.7171 - val_masked_accuracy: 0.4444\n",
            "Epoch 127/200\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.4811 - masked_accuracy: 0.9863 - val_loss: 5.6298 - val_masked_accuracy: 0.4444\n",
            "Epoch 128/200\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.4464 - masked_accuracy: 0.9863 - val_loss: 5.6656 - val_masked_accuracy: 0.4444\n",
            "Epoch 129/200\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.4341 - masked_accuracy: 0.9863 - val_loss: 5.7069 - val_masked_accuracy: 0.4444\n",
            "Epoch 130/200\n",
            "4/4 [==============================] - 0s 120ms/step - loss: 0.4150 - masked_accuracy: 0.9863 - val_loss: 5.7278 - val_masked_accuracy: 0.4444\n",
            "Epoch 131/200\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.3864 - masked_accuracy: 0.9863 - val_loss: 5.7810 - val_masked_accuracy: 0.4444\n",
            "Epoch 132/200\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.3613 - masked_accuracy: 0.9863 - val_loss: 5.7670 - val_masked_accuracy: 0.4444\n",
            "Epoch 133/200\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.3485 - masked_accuracy: 0.9863 - val_loss: 5.7657 - val_masked_accuracy: 0.4444\n",
            "Epoch 134/200\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.3265 - masked_accuracy: 0.9917 - val_loss: 5.7970 - val_masked_accuracy: 0.4444\n",
            "Epoch 135/200\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.3060 - masked_accuracy: 0.9863 - val_loss: 5.8095 - val_masked_accuracy: 0.4444\n",
            "Epoch 136/200\n",
            "4/4 [==============================] - 1s 302ms/step - loss: 0.2901 - masked_accuracy: 0.9917 - val_loss: 5.8558 - val_masked_accuracy: 0.4444\n",
            "Epoch 137/200\n",
            "4/4 [==============================] - 0s 110ms/step - loss: 0.2721 - masked_accuracy: 0.9917 - val_loss: 5.8516 - val_masked_accuracy: 0.4444\n",
            "Epoch 138/200\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.2591 - masked_accuracy: 0.9917 - val_loss: 5.8568 - val_masked_accuracy: 0.4444\n",
            "Epoch 139/200\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.2404 - masked_accuracy: 1.0000 - val_loss: 5.8977 - val_masked_accuracy: 0.5000\n",
            "Epoch 140/200\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.2340 - masked_accuracy: 1.0000 - val_loss: 5.9065 - val_masked_accuracy: 0.4444\n",
            "Epoch 141/200\n",
            "4/4 [==============================] - 0s 114ms/step - loss: 0.2198 - masked_accuracy: 1.0000 - val_loss: 5.9069 - val_masked_accuracy: 0.4444\n",
            "Epoch 142/200\n",
            "4/4 [==============================] - 1s 274ms/step - loss: 0.2102 - masked_accuracy: 1.0000 - val_loss: 5.8507 - val_masked_accuracy: 0.5000\n",
            "Epoch 143/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.1970 - masked_accuracy: 1.0000 - val_loss: 5.9825 - val_masked_accuracy: 0.5000\n",
            "Epoch 144/200\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.1857 - masked_accuracy: 1.0000 - val_loss: 6.0424 - val_masked_accuracy: 0.5000\n",
            "Epoch 145/200\n",
            "4/4 [==============================] - 1s 280ms/step - loss: 0.1867 - masked_accuracy: 1.0000 - val_loss: 6.0012 - val_masked_accuracy: 0.5000\n",
            "Epoch 146/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.1785 - masked_accuracy: 1.0000 - val_loss: 6.0543 - val_masked_accuracy: 0.5000\n",
            "Epoch 147/200\n",
            "4/4 [==============================] - 1s 283ms/step - loss: 0.1769 - masked_accuracy: 1.0000 - val_loss: 6.1188 - val_masked_accuracy: 0.5000\n",
            "Epoch 148/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.1663 - masked_accuracy: 1.0000 - val_loss: 6.2198 - val_masked_accuracy: 0.5000\n",
            "Epoch 149/200\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.1433 - masked_accuracy: 1.0000 - val_loss: 6.2442 - val_masked_accuracy: 0.5000\n",
            "Epoch 150/200\n",
            "4/4 [==============================] - 1s 279ms/step - loss: 0.1342 - masked_accuracy: 1.0000 - val_loss: 6.2916 - val_masked_accuracy: 0.4444\n",
            "Epoch 151/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.1243 - masked_accuracy: 1.0000 - val_loss: 6.3829 - val_masked_accuracy: 0.5000\n",
            "Epoch 152/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.1142 - masked_accuracy: 1.0000 - val_loss: 6.2665 - val_masked_accuracy: 0.5000\n",
            "Epoch 153/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.1045 - masked_accuracy: 1.0000 - val_loss: 6.3013 - val_masked_accuracy: 0.5000\n",
            "Epoch 154/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.1013 - masked_accuracy: 1.0000 - val_loss: 6.2722 - val_masked_accuracy: 0.5000\n",
            "Epoch 155/200\n",
            "4/4 [==============================] - 0s 139ms/step - loss: 0.0915 - masked_accuracy: 1.0000 - val_loss: 6.3088 - val_masked_accuracy: 0.5000\n",
            "Epoch 156/200\n",
            "4/4 [==============================] - 1s 274ms/step - loss: 0.0886 - masked_accuracy: 1.0000 - val_loss: 6.3488 - val_masked_accuracy: 0.5000\n",
            "Epoch 157/200\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.0827 - masked_accuracy: 1.0000 - val_loss: 6.3524 - val_masked_accuracy: 0.5000\n",
            "Epoch 158/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.0779 - masked_accuracy: 1.0000 - val_loss: 6.4263 - val_masked_accuracy: 0.5000\n",
            "Epoch 159/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.0725 - masked_accuracy: 1.0000 - val_loss: 6.4188 - val_masked_accuracy: 0.5000\n",
            "Epoch 160/200\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.0687 - masked_accuracy: 1.0000 - val_loss: 6.4053 - val_masked_accuracy: 0.5000\n",
            "Epoch 161/200\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.0641 - masked_accuracy: 1.0000 - val_loss: 6.4586 - val_masked_accuracy: 0.5000\n",
            "Epoch 162/200\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.0617 - masked_accuracy: 1.0000 - val_loss: 6.5081 - val_masked_accuracy: 0.5000\n",
            "Epoch 163/200\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.0578 - masked_accuracy: 1.0000 - val_loss: 6.5356 - val_masked_accuracy: 0.5000\n",
            "Epoch 164/200\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.0575 - masked_accuracy: 1.0000 - val_loss: 6.5454 - val_masked_accuracy: 0.5000\n",
            "Epoch 165/200\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.0540 - masked_accuracy: 1.0000 - val_loss: 6.6105 - val_masked_accuracy: 0.5000\n",
            "Epoch 166/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.0543 - masked_accuracy: 1.0000 - val_loss: 6.5239 - val_masked_accuracy: 0.5000\n",
            "Epoch 167/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.0636 - masked_accuracy: 0.9947 - val_loss: 6.4806 - val_masked_accuracy: 0.5000\n",
            "Epoch 168/200\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.0855 - masked_accuracy: 0.9894 - val_loss: 6.5740 - val_masked_accuracy: 0.5000\n",
            "Epoch 169/200\n",
            "4/4 [==============================] - 0s 131ms/step - loss: 0.0627 - masked_accuracy: 0.9947 - val_loss: 6.4865 - val_masked_accuracy: 0.5000\n",
            "Epoch 170/200\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.1058 - masked_accuracy: 0.9894 - val_loss: 6.1316 - val_masked_accuracy: 0.4444\n",
            "Epoch 171/200\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.0857 - masked_accuracy: 0.9894 - val_loss: 6.4781 - val_masked_accuracy: 0.5000\n",
            "Epoch 172/200\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.0849 - masked_accuracy: 0.9947 - val_loss: 6.7487 - val_masked_accuracy: 0.5000\n",
            "Epoch 173/200\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.0558 - masked_accuracy: 1.0000 - val_loss: 6.7423 - val_masked_accuracy: 0.4444\n",
            "Epoch 174/200\n",
            "4/4 [==============================] - 0s 120ms/step - loss: 0.0621 - masked_accuracy: 0.9947 - val_loss: 6.8127 - val_masked_accuracy: 0.5000\n",
            "Epoch 175/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.0519 - masked_accuracy: 1.0000 - val_loss: 6.8187 - val_masked_accuracy: 0.5000\n",
            "Epoch 176/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.0419 - masked_accuracy: 1.0000 - val_loss: 6.7294 - val_masked_accuracy: 0.5000\n",
            "Epoch 177/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.0389 - masked_accuracy: 1.0000 - val_loss: 6.8956 - val_masked_accuracy: 0.5000\n",
            "Epoch 178/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.0391 - masked_accuracy: 1.0000 - val_loss: 6.9760 - val_masked_accuracy: 0.5000\n",
            "Epoch 179/200\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.0542 - masked_accuracy: 0.9894 - val_loss: 6.8677 - val_masked_accuracy: 0.5000\n",
            "Epoch 180/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.0333 - masked_accuracy: 1.0000 - val_loss: 6.8476 - val_masked_accuracy: 0.5000\n",
            "Epoch 181/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.0863 - masked_accuracy: 0.9840 - val_loss: 6.8778 - val_masked_accuracy: 0.5000\n",
            "Epoch 182/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.0384 - masked_accuracy: 1.0000 - val_loss: 6.7899 - val_masked_accuracy: 0.5000\n",
            "Epoch 183/200\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.0312 - masked_accuracy: 1.0000 - val_loss: 6.9055 - val_masked_accuracy: 0.5000\n",
            "Epoch 184/200\n",
            "4/4 [==============================] - 1s 297ms/step - loss: 0.0286 - masked_accuracy: 1.0000 - val_loss: 7.0318 - val_masked_accuracy: 0.5000\n",
            "Epoch 185/200\n",
            "4/4 [==============================] - 0s 109ms/step - loss: 0.0244 - masked_accuracy: 1.0000 - val_loss: 7.0216 - val_masked_accuracy: 0.5000\n",
            "Epoch 186/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.0228 - masked_accuracy: 1.0000 - val_loss: 7.0466 - val_masked_accuracy: 0.5000\n",
            "Epoch 187/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.0206 - masked_accuracy: 1.0000 - val_loss: 7.1191 - val_masked_accuracy: 0.5000\n",
            "Epoch 188/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.0186 - masked_accuracy: 1.0000 - val_loss: 7.1398 - val_masked_accuracy: 0.5000\n",
            "Epoch 189/200\n",
            "4/4 [==============================] - 0s 101ms/step - loss: 0.0180 - masked_accuracy: 1.0000 - val_loss: 7.1285 - val_masked_accuracy: 0.5000\n",
            "Epoch 190/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.0162 - masked_accuracy: 1.0000 - val_loss: 7.1830 - val_masked_accuracy: 0.5000\n",
            "Epoch 191/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.0155 - masked_accuracy: 1.0000 - val_loss: 7.2492 - val_masked_accuracy: 0.5000\n",
            "Epoch 192/200\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.0150 - masked_accuracy: 1.0000 - val_loss: 7.2579 - val_masked_accuracy: 0.5000\n",
            "Epoch 193/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.0195 - masked_accuracy: 0.9947 - val_loss: 7.2660 - val_masked_accuracy: 0.5000\n",
            "Epoch 194/200\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.0145 - masked_accuracy: 1.0000 - val_loss: 7.2417 - val_masked_accuracy: 0.5000\n",
            "Epoch 195/200\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.0419 - masked_accuracy: 0.9947 - val_loss: 7.3084 - val_masked_accuracy: 0.5000\n",
            "Epoch 196/200\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.0255 - masked_accuracy: 0.9947 - val_loss: 7.2120 - val_masked_accuracy: 0.5000\n",
            "Epoch 197/200\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.0202 - masked_accuracy: 1.0000 - val_loss: 6.8335 - val_masked_accuracy: 0.5000\n",
            "Epoch 198/200\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.0181 - masked_accuracy: 1.0000 - val_loss: 6.7927 - val_masked_accuracy: 0.5000\n",
            "Epoch 199/200\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.0141 - masked_accuracy: 1.0000 - val_loss: 7.1419 - val_masked_accuracy: 0.5000\n",
            "Epoch 200/200\n",
            "4/4 [==============================] - 0s 91ms/step - loss: 0.0122 - masked_accuracy: 1.0000 - val_loss: 7.2912 - val_masked_accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c3bf15099f0>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "# Fit the model using NumPy arrays\n",
        "transformer.fit(train_dataset,\n",
        "    epochs=200,\n",
        "    validation_data=val_dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Testing**"
      ],
      "metadata": {
        "id": "pz9HJwaaJ7Ka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a directory to save the model\n",
        "model_dir = '/content/drive/MyDrive/Saved_Models'"
      ],
      "metadata": {
        "id": "qECaCVFSw964"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "tf.saved_model.save(transformer, model_dir)"
      ],
      "metadata": {
        "id": "5D71iSor0bHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a saved model (optional)\n",
        "loaded_model = tf.saved_model.load(model_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "Q0AXAUMjyBDs",
        "outputId": "70c49e25-d6ee-49ab-f442-31b13067bb54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ecea14051ffb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokToShow = 2\n",
        "\n",
        "x_in = np.reshape(inputX_train[0, :], (1, MAX_TOKENS))\n",
        "y_in = np.reshape(inputY_train[0, 0:tokToShow], (1, tokToShow))"
      ],
      "metadata": {
        "id": "-25wcBSLlm2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = transformer((x_in, y_in), training=False)[0, -1, :].numpy()\n",
        "outputTok = np.argmax(output)\n",
        "outputTok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "id": "Y6s8NMNDloTR",
        "outputId": "db95b0f5-c0e1-4b7e-a41b-0bf7ae833362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-eb1f8d432807>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutputTok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moutputTok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m_call_attribute\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_call_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/function_deserialization.py\u001b[0m in \u001b[0;36mrestored_function_body\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m           \"Option {}:\\n  {}\\n  Keyword arguments: {}\".format(\n\u001b[1;32m    300\u001b[0m               index + 1, _pretty_format_positional(positional), keyword))\n\u001b[0;32m--> 301\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0;34m\"Could not find matching concrete function to call loaded from the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;34mf\"SavedModel. Got:\\n  {_pretty_format_positional(args)}\\n  Keyword \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Could not find matching concrete function to call loaded from the SavedModel. Got:\n  Positional arguments (1 total):\n    * (<tf.Tensor 'inputs:0' shape=(1, 100) dtype=int32>,\n <tf.Tensor 'inputs_1:0' shape=(1, 2) dtype=int32>)\n  Keyword arguments: {'training': False}\n\n Expected these arguments to match one of the following 2 option(s):\n\nOption 1:\n  Positional arguments (1 total):\n    * (TensorSpec(shape=(None, 100), dtype=tf.int32, name='input_1'),\n TensorSpec(shape=(None, 99), dtype=tf.int32, name='input_2'))\n  Keyword arguments: {'training': True}\n\nOption 2:\n  Positional arguments (1 total):\n    * (TensorSpec(shape=(None, 100), dtype=tf.int32, name='input_1'),\n TensorSpec(shape=(None, 99), dtype=tf.int32, name='input_2'))\n  Keyword arguments: {'training': False}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Responder(tf.Module):\n",
        "  def __init__(self, transformer):\n",
        "    self.transformer = transformer\n",
        "\n",
        "  def __call__(self, sentence, max_length=MAX_TOKENS):\n",
        "    x_in = tokenize_and_pad_training([sentence])[:, 0:MAX_TOKENS]\n",
        "    y_in = np.zeros((1, MAX_TOKENS)).astype(np.int32)\n",
        "    startTok = Vocab[1]\n",
        "    inputToks = [startTok]\n",
        "    outputWords = []\n",
        "    lastTok = 1\n",
        "    tokToShow = 1\n",
        "    while outputTok != 2 and tokToShow < MAX_TOKENS:\n",
        "      y_in[0, tokToShow-1] = lastTok\n"
      ],
      "metadata": {
        "id": "bbbecIE1_38f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'What is the meaning of life?'\n",
        "x_in = tokenize_and_pad_training([sentence])[:, 0:MAX_TOKENS]\n",
        "y_in = np.zeros((1, MAX_TOKENS)).astype(np.int32)\n",
        "startTok = Vocab[1]\n",
        "inputToks = [startTok]\n",
        "outputWords = []\n",
        "lastTok = 1\n",
        "tokToShow = 1\n",
        "while lastTok != 2 and tokToShow < MAX_TOKENS:\n",
        "  y_in[0, tokToShow-1] = lastTok\n",
        "  output = transformer((x_in, y_in), training=False)[0, -1, :].numpy()\n",
        "  lastTok = np.argmax(output)\n",
        "  outputWords.append(Vocab[lastTok, 0])\n",
        "  tokToShow += 1\n",
        "print(\"\".join(outputWords))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "3Bx54MHvC0qA",
        "outputId": "59f65a7b-8ee0-47f0-baf9-5012a8b41a84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-b88e25dd1e3d>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mlastTok\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtokToShow\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mMAX_TOKENS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0my_in\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokToShow\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlastTok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mlastTok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0moutputWords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlastTok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'transformer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ignore"
      ],
      "metadata": {
        "id": "P-CMjWZxJyQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample = 0\n",
        "nextTok = 0\n",
        "outputToks = []\n",
        "outputTok = 0\n",
        "\n",
        "tokToShow = 1\n",
        "while outputTok != 2 and tokToShow < MAX_TOKENS:\n",
        "  x_in = np.reshape(inputX_train[sample, :], (1, MAX_TOKENS))\n",
        "  y_in = np.reshape(inputY_train[sample, 0:tokToShow], (1, tokToShow))\n",
        "  output = transformer((x_in, y_in), training=False)[0, -1, :].numpy()\n",
        "  outputTok = np.argmax(output)\n",
        "  outputToks.append(outputTok)\n",
        "  tokToShow += 1\n",
        "\n"
      ],
      "metadata": {
        "id": "O0CYJE4op-BR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trueToks = np.reshape(trueY[sample, :], (1, MAX_TOKENS-1))\n",
        "print(f'True Tokens: {trueToks}')\n",
        "predToks = np.reshape(np.array(outputToks), (1, len(outputToks)))\n",
        "print(f'Predicted Tokens: {predToks}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vhinwAFs8lG",
        "outputId": "98dae024-4b8d-40b2-d2f9-0a00c728ee72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Tokens: [[   22   138 30086  2849 30086    87 30086   285 30086    93 30086    29\n",
            "  30086 10753 30086   677 30086    95 30086   125 30086   170 30086 20641\n",
            "  30086    92 30086  8524    66     2     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0]]\n",
            "Predicted Tokens: [[   22   138 30086  2849 30086    87 30086   285 30086    93 30086    29\n",
            "  30086 10753 30086   677 30086    95 30086   125 30086   170 30086 20641\n",
            "  30086    92 30086  8524    66     2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving"
      ],
      "metadata": {
        "id": "9vnmrBHVJ1eU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "transformer.save('/content/drive/MyDrive/Transformer_1.hdf5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "otnwNgGPvrGz",
        "outputId": "fa21366c-ecda-4f10-da32-41bdf9eb5e73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-321fbb07eda9>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Transformer_1.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequential\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         ):\n\u001b[0;32m--> 152\u001b[0;31m             raise NotImplementedError(\n\u001b[0m\u001b[1;32m    153\u001b[0m                 \u001b[0;34m\"Saving the model to HDF5 format requires the model to be a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0;34m\"Functional model or a Sequential model. It does not work for \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Speaker(tf.Module):\n",
        "  def __init__(self, transformer):\n",
        "    self.tokenizers = tokenizers\n",
        "    self.transformer = transformer\n",
        "\n",
        "  def __call__(self, sentence, max_length=MAX_TOKENS):\n",
        "    # The input sentence is Portuguese, hence adding the `[START]` and `[END]` tokens.\n",
        "    assert isinstance(sentence, tf.Tensor)\n",
        "    if len(sentence.shape) == 0:\n",
        "      sentence = sentence[tf.newaxis]\n",
        "\n",
        "    sentence = self.tokenizers.pt.tokenize(sentence).to_tensor()\n",
        "\n",
        "    encoder_input = sentence\n",
        "\n",
        "    # As the output language is English, initialize the output with the\n",
        "    # English `[START]` token.\n",
        "    start_end = self.tokenizers.en.tokenize([''])[0]\n",
        "    start = start_end[0][tf.newaxis]\n",
        "    end = start_end[1][tf.newaxis]\n",
        "\n",
        "    # `tf.TensorArray` is required here (instead of a Python list), so that the\n",
        "    # dynamic-loop can be traced by `tf.function`.\n",
        "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
        "    output_array = output_array.write(0, start)\n",
        "\n",
        "    for i in tf.range(max_length):\n",
        "      output = tf.transpose(output_array.stack())\n",
        "      predictions = self.transformer([encoder_input, output], training=False)\n",
        "\n",
        "      # Select the last token from the `seq_len` dimension.\n",
        "      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
        "\n",
        "      predicted_id = tf.argmax(predictions, axis=-1)\n",
        "\n",
        "      # Concatenate the `predicted_id` to the output which is given to the\n",
        "      # decoder as its input.\n",
        "      output_array = output_array.write(i+1, predicted_id[0])\n",
        "\n",
        "      if predicted_id == end:\n",
        "        break\n",
        "\n",
        "    output = tf.transpose(output_array.stack())\n",
        "    # The output shape is `(1, tokens)`.\n",
        "    text = tokenizers.en.detokenize(output)[0]  # Shape: `()`.\n",
        "\n",
        "    tokens = tokenizers.en.lookup(output)[0]\n",
        "\n",
        "    # `tf.function` prevents us from using the attention_weights that were\n",
        "    # calculated on the last iteration of the loop.\n",
        "    # So, recalculate them outside the loop.\n",
        "    self.transformer([encoder_input, output[:,:-1]], training=False)\n",
        "    attention_weights = self.transformer.decoder.last_attn_scores\n",
        "\n",
        "    return text, tokens, attention_weights"
      ],
      "metadata": {
        "id": "d18CpY-gwCGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator = Translator(transformer)"
      ],
      "metadata": {
        "id": "D9hrawNMweAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_translation(sentence, tokens, ground_truth):\n",
        "  print(f'{\"Input:\":15s}: {sentence}')\n",
        "  print(f'{\"Prediction\":15s}: {tokens.numpy().decode(\"utf-8\")}')\n",
        "  print(f'{\"Ground truth\":15s}: {ground_truth}')"
      ],
      "metadata": {
        "id": "xXmoOetVwiL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Other Functions"
      ],
      "metadata": {
        "id": "VGkPTt8-v_NJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8Z7744yUJxU"
      },
      "outputs": [],
      "source": [
        "for (batch, ((x_batch_train, y_batch_train), one_hot_y_batch_train)) in enumerate(train_dataset):\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rr604gsUostX"
      },
      "outputs": [],
      "source": [
        "def speak(input):\n",
        "  global MAX_TOKENS\n",
        "  responses = []\n",
        "  x_in = input\n",
        "  y_in = np.array([[1]])\n",
        "  nextToken = np.argmax(transformer([x_in, y_in], training=False).numpy())\n",
        "  nextWord = Vocab[nextToken,0]\n",
        "  responses.append(nextWord)\n",
        "  numResponses = 1\n",
        "  while nextWord != Vocab[2,:] and numResponses < MAX_TOKENS:\n",
        "    y_in = np.concatenate((y_in, np.reshape(np.array(nextToken), (1,1))), axis=1)\n",
        "    nextToken = np.argmax(transformer([x_in, y_in], training=False).numpy())\n",
        "    nextWord = Vocab[nextToken,0]\n",
        "    responses.append(nextWord)\n",
        "    numResponses += 1\n",
        "  print(\"\".join(responses))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfPep5WepBaO"
      },
      "outputs": [],
      "source": [
        "question = np.reshape(tempX[0], (1, MAX_TOKENS))\n",
        "print(speak(question))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "It8Tjzvxx_Af"
      },
      "outputs": [],
      "source": [
        "x_in = np.reshape(tempX[0], (1, MAX_TOKENS))\n",
        "y_in = np.array([[4]])\n",
        "response = transformer([x_in, y_in], training=False)\n",
        "response_np = response.numpy()\n",
        "idx = np.argmax(response_np)\n",
        "print(idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUHTHhSxehRC"
      },
      "source": [
        "# **Extra Stuff - Reserve**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}